<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jennifer Renoux</title>
    <link>https://jrenoux.github.io/</link>
      <atom:link href="https://jrenoux.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Jennifer Renoux</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sun, 12 Oct 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://jrenoux.github.io/media/logo_huc6f9f266f1d613c2d87b3693fb23c228_47872_300x300_fit_lanczos_3.png</url>
      <title>Jennifer Renoux</title>
      <link>https://jrenoux.github.io/</link>
    </image>
    
    <item>
      <title>Teaching</title>
      <link>https://jrenoux.github.io/teaching/accomplishments/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/teaching/accomplishments/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Paper accepted ! AI Research is not Magic, it has to be Reproducible and Responsible: Challenges in the AI field from the Perspective of its PhD Students</title>
      <link>https://jrenoux.github.io/talks-events/20251013-dighum/</link>
      <pubDate>Sun, 12 Oct 2025 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/talks-events/20251013-dighum/</guid>
      <description>&lt;p&gt;Our new paper about the needs of the AI researchers have been accepted for presentation at the Digital Humanism conference. In this paper, we start from the observation that research needs to be reproducible and responsible, and that Ph.D. students are often the ones taking the burden of reproducibility. We therefore interviewed 28 of them and conducted a qualitative analysis to identify the commonly encountered pain points. We found out that despite many existing initiatives, research in AI still fails to be reproducible. We discuss the impact of this irreproducibility on the field and propose recommendations for institutions and the field in general to facilitate reproducible and responsible AI research.&lt;/p&gt;
&lt;p&gt;You can access the pre-print of this paper &lt;a href=&#34;https://jrenoux.github.io/uploads/papers/digihum-2025.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Who shapes the future with AI - My talk at DoSpace Ã–rebro</title>
      <link>https://jrenoux.github.io/talks-events/20251009-dospace/</link>
      <pubDate>Fri, 10 Oct 2025 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/talks-events/20251009-dospace/</guid>
      <description>&lt;p&gt;Following my &lt;a href=&#34;https://www.na.se/2025-04-11/darfor-ar-ai-en-politisk-fraga-som-angar-dig/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;recent article for the Swedish Newspaper Nerikes Allehanda&lt;/a&gt; (that you can find in English &lt;a href=&#34;https://jrenoux.github.io/popular-science/ai-is-political-issue/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;), Iâ€¯ have been invited to talk about AI and how it shapes the future (and through whom) at &lt;a href=&#34;https://dospace.se/orebro/dospace-sodercity-orebro/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DoSpace Ã–rebro&lt;/a&gt;, a co-working company that just cebrated its first year in Ã–rebro.
In this talk, I started with a short introduction to what AI is in order to give the audience (non-specialists) an idea of what we are actually working on when we talk about AI. I then provided some information about ethical issues related to AI (we could only scratch the surface!), and went on to discuss who is currently talking on the world stage and what their narrative was.
I advocated for a change of narrative and a more inclusive discussion around AI. Currently, the general public is absent from the discussion about AI and its future, even though it is directly impacted. I believe (and argued) that AI must become a political question the same way economy, social welfare, or ecology are political questions. And that this does not mean that everyone must become an expert in AI but that we are in critical need of critical AI literacy.&lt;/p&gt;
&lt;p&gt;You can access the slides of my talk &lt;a href=&#34;https://jrenoux.github.io/uploads/talks/20251009-dospace-slides.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A bit thank you to &lt;a href=&#34;https://dospace.se/orebro/dospace-sodercity-orebro/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DoSpace&lt;/a&gt; for inviting me and the very interesting discussions that followed the presentation!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How do we communicate with robots?</title>
      <link>https://jrenoux.github.io/popular-science/how-communicate-robot/</link>
      <pubDate>Fri, 22 Aug 2025 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/popular-science/how-communicate-robot/</guid>
      <description>&lt;h2 id=&#34;i-have-been-writing-for-na-again-this-time-about-how-we-communicate-with-robots-the-article-in-swedish-is-available-herehttpswwwnase2025-08-22sa-kommunicerar-du-med-en-robot-in-this-page-is-the-english-version--enjoy-&#34;&gt;I have been writing for NA again! This time about how we communicate with robots. The article in Swedish is available &lt;a href=&#34;https://www.na.se/2025-08-22/sa-kommunicerar-du-med-en-robot/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;. In this page is the English version ! Enjoy !&lt;/h2&gt;
&lt;p&gt;How do you know how to communicate? Communication is universal and innate. We were all born with the ability to communicate, and all humans do communicate. Animals communicate. Even plants communicate. We also see inter-species communication. We communicate with animals. But communication is also cultural and socially constructed. We do not communicate the same way in Sweden, in Japan, or in South Africa. We do not communicate the same way if we come from a rich or poor background. We do not communicate the same way at 10, 40, or 65 years old. And teenagers today certainly do not communicate the same way teenagers communicated 40 years ago.&lt;/p&gt;
&lt;p&gt;So what happens when our communication partner is not a human or an animal anymore, as it has been for millennia, but a robot? Robots, and more generally Artificial Intelligence, are strange entities. They are obviously not alive, but they are programmed to show some form of agency. So how do we communicate with an AI? As a researcher in Human-AI communication, this question is the core of my research interests.&lt;/p&gt;
&lt;p&gt;When we communicate with an AI, we will naturally employ some of the communication habits and constructs that we have learned during our previous interactions with humans and animals to guide us. We will try to make sense of this unknown partner through previous experiences. To do this, we will get influenced by how the AI looks and behave. If it looks childish, or cartoonish, we may talk to it as we would talk to a child. We will communicate to animal-resembling robots like we would with a pet. We will say &amp;ldquo;please&amp;rdquo; and &amp;ldquo;thank you&amp;rdquo; to ChatGPT. And while research has shown that drawing from these previous experiences might in fact help human-AI communication, it has also shown that we are not communicating exactly the same way with AI than we do with humans. For instance, a study in 2017 investigated how people interacted with an AI chatbot on a well-known social media compared to interactions with other humans. They figured out that humans employed different strategies when communicating with the AI than with the humans.&lt;/p&gt;
&lt;p&gt;How the AIâ€¯system is programmed also has a strong impact on how a user will communicate with it. The persona displayed by an AI influences what characteristics we attribute to it. Does it present more male or female, is it friendly, assertive, arrogant? Is it more robotic or more human-like? And these decisions are entirely controlled by the people who develop these systems. An AI does not have the experience of a human being to draw from. It is a blank sheet on which a team of researchers and developers decide to write their ideas and values. And currently, the big push in the research community is to make communicative AI as human-like and &amp;ldquo;natural&amp;rdquo; as possible to facilitate communication. Researchers and engineers develop systems that communicate using language, that can show emotions and social cues in a natural way, all of this to make the interaction as natural as possible. But natural for whom?&lt;/p&gt;
&lt;p&gt;Have you ever heard of the W.E.I.R.D. acronym? It stands for &amp;ldquo;Western, Educated, Industrialized, Rich, Democratic.&amp;rdquo; It has been coined by the American anthropologist Joseph Heinrich and his collaborators, and  is used as way to summarize the background of most participants in psychological research, and by extension in Human-AI Interaction research. Most participants (and in fact, researchers) in these fields come from countries in the &amp;ldquo;West&amp;rdquo; (Western Europe or North America), with a high level of education, that are highly industrialized, globally rich, and generally democratic. His research has also shown that there are a lot of psychological differences between populations around the world and that W.E.I.R.D. populations are quite peculiar in their psychology. Therefore, the results drawn from research on these participants are not necessarily applicable to the population in all its diversity.&lt;/p&gt;
&lt;p&gt;This diversity issue also holds for other aspects of peopleâ€™ life, and to the W.E.I.R.D. classification, I would also like to add &amp;ldquo;Able-bodied,&amp;rdquo; &amp;ldquo;Neurotypical,&amp;rdquo; and &amp;ldquo;English-speaking.&amp;rdquo; Research and development often fails to account for people with disabilities or neurodivergent, except when developing systems to &amp;ldquo;help&amp;rdquo; them. But on the contrary, systems most often end up exclusionary. Recent work has examined the guidelines that constructors were implementing in voice activated personal assistants (like Siri, Amazonâ€™s Alexa, Googleâ€™s Echo&amp;hellip;). And they figured out that these guidelines are actively making usability worse for blind and visually impaired users. Blind and visually impaired users benefit greatly from voice assistants for every day tasks. But they also are able to process much faster speech and much more complex spoken sentences than sighted users. By trying to make the interaction more &amp;ldquo;natural&amp;rdquo; and using sighted people as default users, researchers and engineers exclude a very large part of the population. Another example is how ChatGPT fails to appropriately answer to people who speak dialects of English that are not American or British English. It usually ends up exaggerating the languageâ€™s features, failing to recognize the appropriate tone, thus answering in a far too formal way. Which in turn make the user feel uncomfortable and the tool feel useless.&lt;/p&gt;
&lt;p&gt;If we fail to take a large view on diversity, we will exclude a lot of people from the tool we develop. I want to advocate for a much wider view of human-AI communication. Spoken and written texts are not and should not be the ultimate medium for communication, especially when it comes to communicating with an AI system. Images, sounds, gestures, touch, are as many communication modalities that should be explored. So really, &lt;strong&gt;how&lt;/strong&gt; are we going to communicate with AI?&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Effect of Agent-Based Feedback on Prosociality in Social Dilemmas</title>
      <link>https://jrenoux.github.io/publication/renoux-2025-effect/</link>
      <pubDate>Fri, 23 May 2025 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/renoux-2025-effect/</guid>
      <description></description>
    </item>
    
    <item>
      <title>AI is a political topic - and it concerns you too</title>
      <link>https://jrenoux.github.io/popular-science/ai-is-political-issue/</link>
      <pubDate>Fri, 11 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/popular-science/ai-is-political-issue/</guid>
      <description>&lt;p&gt;Note : two versions of this article have been created and published, one in Swedish published in &lt;a href=&#34;https://www.na.se/2025-04-11/darfor-ar-ai-en-politisk-fraga-som-angar-dig/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Nerikes Allehanda&lt;/a&gt;, and one in Frence published in &lt;a href=&#34;https://blogs.mediapart.fr/jennifer-renoux/blog/280425/lintelligence-artificielle-doit-devenir-une-consideration-citoyenne&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Le Club Mediapart&lt;/a&gt;. Note that this post is not an exact translation of these two articles but the original English version. The final articles have been shortened to fit the other newspapers format.&lt;/p&gt;
&lt;p&gt;&amp;ndash;&lt;/p&gt;
&lt;p&gt;We are being influenced by non-human entities that imitate humans, infiltrate human society, working on behalf of unknown organizations. Our opinions, our actions, our lives are being influenced by these entities. They are everywhere, in our home, at work, in our hospitals.
This is not the plot of a new Hollywood movie, nor some conspiratory rambling about a secret alien society. This is our world since the popularization of Artificial Intelligence (AI).&lt;/p&gt;
&lt;p&gt;Even though the entire world started to talk about Artificial Intelligence a bit more than 2 years ago with the release of ChatGPT, AI has been with us for much longer than that.
AI systems have been introduced in our lives with or without our knowledge and consent. Netflix or Spotifyâ€™s recommendation algorithms, who suggests you the next movie to watch or a nice playlist to listen to, are everyday examples. But more algorithms are impacting our lives than we think. Did you know that your mortgage request might have been granted by an AI system? Or that your resume might have been rejected by an AI? Or that the photo that stirred your emotion on the news outlet you read yesterday was AI generated?&lt;/p&gt;
&lt;p&gt;We are being exposed to AI, whether we want it or not. And AI is not neutral. People create or use an AI system to solve a problem. This could be too many mortgage requests or resumes  to go through for one person, the difficulty to find the right photo to reflect the tone of the article or even the intention to manipulate the readerâ€™s emotion. But how the system actually ends up working depends on a social context : what the solution is supposed to look like, the data that is used to create this solution, the values that the systemâ€™s creator wants to uphold. And creators donâ€™t always anticipate all the consequences of their choices.&lt;/p&gt;
&lt;p&gt;Algorithmic bias is the concept that an algorithm systematically creates unfair outcomes, privileging one group of people over another, usually in ways that are not the intended function of the algorithm. Common examples are &lt;a href=&#34;https://www.reuters.com/article/world/insight-amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK0AG/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Amazonâ€™s recruiting tool that discriminated against women&lt;/a&gt;, &lt;a href=&#34;http://gendershades.org/overview.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;facial recognition algorithms that do not differentiate between different black persons&lt;/a&gt;, or &lt;a href=&#34;https://www.science.org/doi/10.1126/science.aax2342&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;medical systems that underestimate the medical needs of minorities&lt;/a&gt;. Algorithmic bias can have multiple causes. Often people will attribute this to data :â€¯if the data is biased, the system will be too. While this is true, it would be a mistake to think that data is the only culprit. For instance, in the United State, &lt;a href=&#34;https://www.science.org/doi/10.1126/science.aax2342&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;hospitals have been using an AI system&lt;/a&gt; to help them decide whether an incoming patient should be sent to the emergency room or not based on their medical history. Understanding the medical history of a patient is a very complex problem, and the developers of the algorithm made the assumption that people with a severe medical history will spend more money on healthcare than others. They therefore used the amount ofâ€¯money previously spent on healthcare as a substitute for medical history. However, due to socio-economical reasons, black Americans spend on average less money on healthcare than white Americans with similar needs. Therefore, the algorithm systematically underestimated black Americanâ€™s medical needs. Data itself is not the issue here.
It is important to note that algorithmic biases go much further than sexist or racist biases. For instance, researchers have been studying &lt;a href=&#34;https://arxiv.org/abs/2406.08818&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;linguistic biases in ChatGPT&lt;/a&gt; and demonstrated that it is stereotyping dialects, which made users of these dialects feel uncomfortable and insulted.  Cultural biases or misrepresentations are other issues associated to AI systems.&lt;/p&gt;
&lt;p&gt;Why does it matter? After all, if we know these systems are biased, canâ€™t we check the output ourselves and make our own mind? Unfortunately, it is not that simple. We all have a tendency to favor decisions made with automation compared to decision made without. This is called automation bias, and is well studied in psychology. This means that when AI systems present us with a solution, we are naturally inclined to adopt this solution. Yes, this applies even if you are aware that automation bias is a thing. Furthermore, researchers have also shown that using AI systems directly impacts our opinions. &lt;a href=&#34;https://arxiv.org/abs/2302.00560&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;In a study&lt;/a&gt;, a language model was programmed to promote a specific opinion towards social media. Participants who used this model wrote pieces that followed the promoted opinion, and even had their own stance towards social media influenced by the model. This is a frightening find. More and more text is being written with the help of ChatGPT and other AI assistants, and we have no control over the opinions programmed in them. Beyond text, AI systems are creating images, moderating content, and generally following rules and algorithms that we have no control over and belong to a handful of very rich companies. What we see, what we read, what we and our children take as role models. All of that is being fed to us by AIs, and we have no say in it.&lt;/p&gt;
&lt;p&gt;Or do we?&lt;/p&gt;
&lt;p&gt;AI must become a citizen concern. As we vote about economy, environment, social policies, we must also vote about AI, its development and its adoption. We donâ€™t need to become AI experts any more that we needed to become geopolitical experts, or financial experts. However, we have a duty to educate ourselves, to understand who is talking about AI on the worldâ€™s stage and wonder about the consequences of what they are saying. We must reflect on what we want and how we want it to be. AI is now, more than ever, political. We cannot remain the passive observers of what is happening to us. We can and must have a say in it.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The CHAI Workshop is coming back in MalmÃ¶ in June</title>
      <link>https://jrenoux.github.io/talks-events/20240315-chai-hhai/</link>
      <pubDate>Sat, 09 Mar 2024 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/talks-events/20240315-chai-hhai/</guid>
      <description>&lt;p&gt;Our Workshop on Communication in Human-AI Interaction will be held in MalmÃ¶, Sweden on June 10. The goal of this one-day workshop is to bring together experts from AI, HCI, and Cognitive Sciences to explore and understand the specificities and characteristics of communication in human-AI interactions, as well as the salient principles, methods, and theories one has to consider to build meaningful human-AI communication systems. As the study of communication in human-AI interaction is by essence a multidisciplinary approach, we aim for this workshop to be a multidisciplinary platform where researchers can learn to work together and pave the way to impacting research.&lt;/p&gt;
&lt;p&gt;Have a look at our &lt;a href=&#34;https://chai-workshop.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;website&lt;/a&gt;. and consider submitting a paper!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Visual Noun Modifiers: The Problem of Binding Visual and Linguistic Cues</title>
      <link>https://jrenoux.github.io/publication/faridghasemnia-2024-visual/</link>
      <pubDate>Thu, 01 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/faridghasemnia-2024-visual/</guid>
      <description></description>
    </item>
    
    <item>
      <title>When Should I Lead or Follow: Understanding Initiative Levels in Human-AI Collaborative Gameplay</title>
      <link>https://jrenoux.github.io/publication/lobo-2024-when/</link>
      <pubDate>Thu, 01 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/lobo-2024-when/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Paper accepted ! From Corrective to Empowering Technologies: Integrating Critical Perspectives in Social Robotics for Autism</title>
      <link>https://jrenoux.github.io/talks-events/20231207-interhai/</link>
      <pubDate>Thu, 30 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/talks-events/20231207-interhai/</guid>
      <description>&lt;p&gt;Our new extended abstract titled &amp;ldquo;From Corrective to Empowering Technologies: Integrating Critical Perspectives in Social Robotics for Autism&amp;rdquo; has been accepted for presentation at the Inter.HAI workshop! In this paper, we look at how the social robotics field usually look at autism as a problem that needs to be corrected, and introduce two approaches that are of interest for social robotics researchers who want to adopt a more critical approach. You can access the paper &lt;a href=&#34;https://jrenoux.github.io/uploads/papers/interhai-2023-cei-jrx.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Large Language Models &#43; Giant AI Experiments = A Whole New World?</title>
      <link>https://jrenoux.github.io/talks-events/20231019-linnaeus-university/</link>
      <pubDate>Thu, 19 Oct 2023 10:10:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/talks-events/20231019-linnaeus-university/</guid>
      <description>&lt;p&gt;On October 19th, I gave a talk at the Research Seminar eHealth Series, organized by Health Data Sweden, about LLM and how they change (or not) the world we are living in.&lt;/p&gt;
&lt;p&gt;Thanks a lot to the organizers for inviting me! You can find the slides of my presentation &lt;a href=&#34;https://jrenoux.github.io/uploads/talks/20231019-llm-linnaeus.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Beyond the Hype: Perspectives on the use of AI and LLM at the university</title>
      <link>https://jrenoux.github.io/talks-events/oru-business-school/</link>
      <pubDate>Tue, 29 Aug 2023 16:45:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/talks-events/oru-business-school/</guid>
      <description>&lt;p&gt;On August 23rd, I had the pleasure of talking in front of Ã–rebro University&amp;rsquo;s buisness school about LLM, what they are, and how they may change our university work.&lt;/p&gt;
&lt;p&gt;Thanks a lot to the organizers for inviting me! You can find the slides of my presentation &lt;a href=&#34;https://jrenoux.github.io/uploads/talks/ethics-ai-llm-university.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>From Corrective to Empowering Technologies: Integrating Critical Perspectives in Social Robotics for Autism</title>
      <link>https://jrenoux.github.io/publication/elmadagli-2023-from/</link>
      <pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/elmadagli-2023-from/</guid>
      <description></description>
    </item>
    
    <item>
      <title>From Reactive to Active Sensing: A Survey on Information Gathering in Decision-Theoretic Planning</title>
      <link>https://jrenoux.github.io/publication/veiga-2023-from/</link>
      <pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/veiga-2023-from/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Paper accepted ! &#34;From Reactive to Active Sensing: a Survey on Information Gathering in Decision-Theoretic Planning</title>
      <link>https://jrenoux.github.io/talks-events/csur-23/</link>
      <pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/talks-events/csur-23/</guid>
      <description>&lt;p&gt;Our new paper titled &amp;ldquo;From Reactive to Active Sensing: a Survey on Information Gathering in Decision-Theoretic Planning&amp;rdquo; has ben accepted for publication in ACM Computing Survey.&lt;/p&gt;
&lt;p&gt;In this paper, we looked at how previous work tackled the problem of information gathering in MDP-based system. Indeed, in most cases, information gathering is simply a mean to a goal. When it becomes the goal, such as in search and rescue or surveillance scenarios, traditional decision-theoretic systems cannot model the problem effectively. Many researchers have searched ways to circumvent this problem. We distinguished two different approaches:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Reactive Sensing : where the model makes use of &amp;ldquo;external stimuli&amp;rdquo; to &amp;ldquo;trick&amp;rdquo; the agent to gather information. This approach is often very application-dependent, and does not allow to reason on the lack of informtaion as information in itself.&lt;/li&gt;
&lt;li&gt;Active Sensing : where the model actually incorporates reasoning about information states. This approach has the advantage to explicety reason about information gain (and the lack of thereof) but at the cost of complexity. We also observed that it is in fact very seldom applied to real-life scenarios.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I hope that this read will interest you and do not hesitate to get in touch if you want to chat about this!&lt;/p&gt;
&lt;p&gt;Jennifer&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Seeking at-home long-term autonomy of assistive mobile robots through the integration with an IoT-based monitoring system</title>
      <link>https://jrenoux.github.io/publication/luperto-2023-seeking/</link>
      <pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/luperto-2023-seeking/</guid>
      <description></description>
    </item>
    
    <item>
      <title>VR Project Grant Accepted</title>
      <link>https://jrenoux.github.io/talks-events/vr-2022/</link>
      <pubDate>Tue, 08 Nov 2022 10:22:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/talks-events/vr-2022/</guid>
      <description>&lt;p&gt;The project proposal I&amp;rsquo;m leading, titled &amp;ldquo;Adaptive Communication Planning for Collaborative AI&amp;rdquo;, has been funded by the Swedish National Research Council (VetenskaprÃ¥det).&lt;/p&gt;
&lt;p&gt;To understand this project&amp;rsquo;s scope, imagine that you are newly employed in a company that uses three types of intelligent machines to assist workers in their various tasks. You have never worked with these machines before. For your first task, you must extract fuel samples from multiple trucks and use the machineâ€™s sensors to analyze them for predictive maintenance. The first machine will only give you information about the task if you ask for it. You are at high risk of missing important information if you donâ€™t know the right question to ask, such as the fact that you should only collect samples on trucks that have not been used for at least an hour.&lt;/p&gt;
&lt;p&gt;The second machine will give you information proactively, but can only explain how the entire task should be carried out, from the beginning and regardless of what you can and cannot perform. It will always instruct you to select a truck that has been unused for at least an hour, then collect the sample with the dedicated device, then place the sample on the machineâ€™s analyzer, then turn on the robotâ€™s analyzing program, etc. While this information makes sense the first time you interact with the machine, it becomes quickly irrelevant and cumbersome in the long term.&lt;/p&gt;
&lt;p&gt;The third machine has been tailored to your needs: your preferences, your level of expertise, your skills, your abilities and will give you precisely the right amount and type of information. However, if you happen to leave the company or miss some days of work, no one will be able to use this machine until it is reconfigured, which is a costly and cumbersome operation.&lt;/p&gt;
&lt;p&gt;It seems obvious that none of these three machines constitute the ideal partner for a collaborative task in a multi-user environment. This, however, is the current state of the art in
human-machine communication. In this project, we propose to realize intelligent agents that combine all three machine&amp;rsquo;s communication skills.&lt;/p&gt;
&lt;p&gt;Our vision with this project is to advance the field of collaborative Artificial Intelligence, i.e., the development of artificially intelligent agents that can interact with humans, leveraging their strengths and compensating for their weaknesses.  Adaptive purposeful communication planning, i.e., the ability to plan communication actions to a given goal and adapt them to changing contexts and users, is a crucial component for collaborative AI and the central topic of this project.&lt;/p&gt;
&lt;p&gt;If this sounds interesting to you, stay tuned as we will soon start the recruitment of a Ph.D. student!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>AI Ethic for Engineers, Swedsoft</title>
      <link>https://jrenoux.github.io/talks-events/swedsoft/</link>
      <pubDate>Tue, 20 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/talks-events/swedsoft/</guid>
      <description>&lt;p&gt;On Sept. 6, 2022, I had the pleasure of presenting an Introduction to AI Ethics and Engineer at one of Swedsoft Seminars. Swedsoft gathers organizations from all over Sweden who are interested in software development.&lt;/p&gt;
&lt;p&gt;Thanks a lot to the organizers for inviting me! You can find the slides of my presentation &lt;a href=&#34;https://jrenoux.github.io/uploads/talks/swedsoft-slides.pdf&#34;&gt;here&lt;/a&gt; and more information about this event at &lt;a href=&#34;https://www.swedsoft.se/en/2022/09/26/ai-and-ethics-for-engineer/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Swedsoft website&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Cultu-RO-MAN</title>
      <link>https://jrenoux.github.io/talks-events/cultu-roman/</link>
      <pubDate>Tue, 30 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/talks-events/cultu-roman/</guid>
      <description>&lt;p&gt;On August 25, 2022, we hosted the Cultu-ro workshsop at Ro-MAN 2022. The workshop will focused on the cultural influences in human-robot interaction. Robots have the potential to improve services in areas such as eldercare, rehabilitation, training, and education.&lt;/p&gt;
&lt;p&gt;More information and detail of the program available &lt;a href=&#34;https://sites.google.com/view/culturo-roman22/home&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;on the workshop website&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>CHAI@IJCAI-ECAI 2022</title>
      <link>https://jrenoux.github.io/talks-events/chai-ijcai/</link>
      <pubDate>Mon, 01 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/talks-events/chai-ijcai/</guid>
      <description>&lt;p&gt;On July 24, 2022, we hosted the first workshop on Communication in Human-AI Interaction (CHAI) at the 31st International Joint Conference on Artificial Intelligence (IJCAI 2022). The goal of this one-day workshop was to bring together experts from AI, HCI, and Cognitive Sciences to explore and understand the specificities and characteristics of communication in human-AI interactions, as well as the salient principles, methods, and theories one has to consider to build meaningful human-AI communication systems.&lt;/p&gt;
&lt;p&gt;We attended 8 paper presentations, as well as two very inspiring keynotes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Nicolas Fay&lt;/strong&gt;, Associate Professor of Cognitive Sciences, presented to us the Role of Iconicity and Embodiment to the Evolution of Human Communication.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Mark Riedl&lt;/strong&gt;, Professor in Artificial Intelligence, argumed for Automated Story Generation as a Lens for Fundamental Artificial Intelligence.&lt;/p&gt;
&lt;p&gt;We were very glad to have a very good attendance and fantastic discussions. Thanks to the organizing team, the PC members, and all the participants for making this event a success!&lt;/p&gt;
&lt;p&gt;The link to the accepted papers and the slides of our keynotes are available on the &lt;a href=&#34;https://chai-workshop.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;workshop website&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Stay tuned, for a 2023 edition might be coming! ðŸ˜‰&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Integrating Social Assistive Robots, IoT, Virtual Communities and Smart Objects to Assist at-Home Independently Living Elders: the MoveCare Project</title>
      <link>https://jrenoux.github.io/publication/luperto-2022-integrating/</link>
      <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/luperto-2022-integrating/</guid>
      <description></description>
    </item>
    
    <item>
      <title>User feedback and remote supervision for assisted living with mobile robots: A field study in long-term autonomy</title>
      <link>https://jrenoux.github.io/publication/luperto-2022-user/</link>
      <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/luperto-2022-user/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Unified Decision-Theoretic Model for Information Gathering and Communication Planning</title>
      <link>https://jrenoux.github.io/publication/renoux-2020-unified/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/renoux-2020-unified/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Virtual Caregiver for Assisted Daily Living of Pre-frail Users</title>
      <link>https://jrenoux.github.io/publication/renoux-2020-virtual/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/renoux-2020-virtual/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Open-Source Data Collection and Data Sets for Activity Recognition in Smart Homes</title>
      <link>https://jrenoux.github.io/publication/kockemann-2020-open/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/kockemann-2020-open/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Users&#39; Concern for Privacy in Context-Aware Reasoning Systems</title>
      <link>https://jrenoux.github.io/publication/forstmann-2020-users/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/forstmann-2020-users/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://jrenoux.github.io/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-wowchemy&#34;&gt;Create slides in Markdown with Wowchemy&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wowchemy&lt;/a&gt; | &lt;a href=&#34;https://wowchemy.com/docs/content/slides/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://revealjs.com/pdf-export/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;porridge&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;blueberry&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;porridge&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;blueberry&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Eating...&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% fragment %}} One {{% /fragment %}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% fragment %}} **Two** {{% /fragment %}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% fragment %}} Three {{% /fragment %}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;span class=&#34;fragment &#34; &gt;
  One
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
  &lt;strong&gt;Two&lt;/strong&gt;
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
  Three
&lt;/span&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% speaker_note %}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;-&lt;/span&gt; Only the speaker can read these notes
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;-&lt;/span&gt; Press &lt;span class=&#34;sb&#34;&gt;`S`&lt;/span&gt; key to view
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  {{% /speaker_note %}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;slide&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;background-image&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;/media/boards.jpg&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;slide&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;background-color&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;#0000FF&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;slide&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;class&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;my-style&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-css&#34; data-lang=&#34;css&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;reveal&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;section&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;h1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;reveal&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;section&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;h2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;reveal&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;section&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;h3&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;color&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;navy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://discord.gg/z8wNYzb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/docs/content/slides/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The MOVECARE project: Home-based monitoring of frailty</title>
      <link>https://jrenoux.github.io/publication/lunardini-2019-movecare/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/lunardini-2019-movecare/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Online Guest Detection in a Smart Home using Pervasive Sensors and Probabilistic Reasoning</title>
      <link>https://jrenoux.github.io/publication/renoux-2018-online/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/renoux-2018-online/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Seeking Prevention of Cognitive Decline in Elders via Activity Suggestion by A Virtual Caregiver.</title>
      <link>https://jrenoux.github.io/publication/vuono-2018-seeking/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/vuono-2018-seeking/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Simulating Daily Activities in a Smart Home for Data Generation</title>
      <link>https://jrenoux.github.io/publication/renoux-2018-simulating/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/renoux-2018-simulating/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Active Situation Reporting: Definition and Analysis</title>
      <link>https://jrenoux.github.io/publication/renoux-2017-active/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/renoux-2017-active/</guid>
      <description></description>
    </item>
    
    <item>
      <title>An ontology-based context-aware system for smart homes: E-care@ home</title>
      <link>https://jrenoux.github.io/publication/alirezaie-2017-ontology/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/alirezaie-2017-ontology/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Context recognition in multiple occupants situations: Detecting the number of agents in a smart home environment with simple sensors</title>
      <link>https://jrenoux.github.io/publication/renoux-2017-context/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/renoux-2017-context/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Towards a synergy of qualitative spatio-temporal reasoning and smart environments for assisting the elderly at home</title>
      <link>https://jrenoux.github.io/publication/sioutis-2017-towards/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/sioutis-2017-towards/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A decision-theoretic planning approach for multi-robot exploration and event search</title>
      <link>https://jrenoux.github.io/publication/renoux-2015-decision/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/renoux-2015-decision/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Contribution to multiagent planning for active information gathering</title>
      <link>https://jrenoux.github.io/publication/renoux-2015-contribution/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/renoux-2015-contribution/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Method For Obtaining A System For Active, Decentralized Multi-agent Situation Control</title>
      <link>https://jrenoux.github.io/publication/renoux-2015-method/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/renoux-2015-method/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Distributed Decision-Theoretic Model for Multiagent Active Information Gathering</title>
      <link>https://jrenoux.github.io/publication/renoux-2014-distributed/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/renoux-2014-distributed/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Un modÃ¨le de dÃ©cision distribuÃ© pour la collecte d&#39;information active multiagents</title>
      <link>https://jrenoux.github.io/publication/renoux-2014-modele/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/renoux-2014-modele/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Affective computing: validation analytique et expÃ©rimentale</title>
      <link>https://jrenoux.github.io/publication/renoux-2011-affective/</link>
      <pubDate>Sat, 01 Jan 2011 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/renoux-2011-affective/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://jrenoux.github.io/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/admin/config.yml</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
