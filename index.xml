<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jennifer Renoux</title>
    <link>https://jrenoux.github.io/</link>
      <atom:link href="https://jrenoux.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Jennifer Renoux</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Fri, 23 May 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://jrenoux.github.io/media/logo_huc6f9f266f1d613c2d87b3693fb23c228_47872_300x300_fit_lanczos_3.png</url>
      <title>Jennifer Renoux</title>
      <link>https://jrenoux.github.io/</link>
    </image>
    
    <item>
      <title>Teaching</title>
      <link>https://jrenoux.github.io/teaching/accomplishments/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/teaching/accomplishments/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The Effect of Agent-Based Feedback on Prosociality in Social Dilemmas</title>
      <link>https://jrenoux.github.io/publication/renoux-2025-effect/</link>
      <pubDate>Fri, 23 May 2025 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/renoux-2025-effect/</guid>
      <description></description>
    </item>
    
    <item>
      <title>AI is a political topic - and it concerns you too</title>
      <link>https://jrenoux.github.io/popular-science/ai-is-political-issue/</link>
      <pubDate>Fri, 11 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/popular-science/ai-is-political-issue/</guid>
      <description>&lt;p&gt;Note : two versions of this article have been created and published, one in Swedish published in &lt;a href=&#34;https://www.na.se/2025-04-11/darfor-ar-ai-en-politisk-fraga-som-angar-dig/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Nerikes Allehanda&lt;/a&gt;, and one in Frence published in &lt;a href=&#34;https://blogs.mediapart.fr/jennifer-renoux/blog/280425/lintelligence-artificielle-doit-devenir-une-consideration-citoyenne&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Le Club Mediapart&lt;/a&gt;. Note that this post is not an exact translation of these two articles but the original English version. The final articles have been shortened to fit the other newspapers format.&lt;/p&gt;
&lt;p&gt;&amp;ndash;&lt;/p&gt;
&lt;p&gt;We are being influenced by non-human entities that imitate humans, infiltrate human society, working on behalf of unknown organizations. Our opinions, our actions, our lives are being influenced by these entities. They are everywhere, in our home, at work, in our hospitals.
This is not the plot of a new Hollywood movie, nor some conspiratory rambling about a secret alien society. This is our world since the popularization of Artificial Intelligence (AI).&lt;/p&gt;
&lt;p&gt;Even though the entire world started to talk about Artificial Intelligence a bit more than 2 years ago with the release of ChatGPT, AI has been with us for much longer than that.
AI systems have been introduced in our lives with or without our knowledge and consent. Netflix or Spotify’s recommendation algorithms, who suggests you the next movie to watch or a nice playlist to listen to, are everyday examples. But more algorithms are impacting our lives than we think. Did you know that your mortgage request might have been granted by an AI system? Or that your resume might have been rejected by an AI? Or that the photo that stirred your emotion on the news outlet you read yesterday was AI generated?&lt;/p&gt;
&lt;p&gt;We are being exposed to AI, whether we want it or not. And AI is not neutral. People create or use an AI system to solve a problem. This could be too many mortgage requests or resumes  to go through for one person, the difficulty to find the right photo to reflect the tone of the article or even the intention to manipulate the reader’s emotion. But how the system actually ends up working depends on a social context : what the solution is supposed to look like, the data that is used to create this solution, the values that the system’s creator wants to uphold. And creators don’t always anticipate all the consequences of their choices.&lt;/p&gt;
&lt;p&gt;Algorithmic bias is the concept that an algorithm systematically creates unfair outcomes, privileging one group of people over another, usually in ways that are not the intended function of the algorithm. Common examples are &lt;a href=&#34;https://www.reuters.com/article/world/insight-amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK0AG/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Amazon’s recruiting tool that discriminated against women&lt;/a&gt;, &lt;a href=&#34;http://gendershades.org/overview.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;facial recognition algorithms that do not differentiate between different black persons&lt;/a&gt;, or &lt;a href=&#34;https://www.science.org/doi/10.1126/science.aax2342&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;medical systems that underestimate the medical needs of minorities&lt;/a&gt;. Algorithmic bias can have multiple causes. Often people will attribute this to data : if the data is biased, the system will be too. While this is true, it would be a mistake to think that data is the only culprit. For instance, in the United State, &lt;a href=&#34;https://www.science.org/doi/10.1126/science.aax2342&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;hospitals have been using an AI system&lt;/a&gt; to help them decide whether an incoming patient should be sent to the emergency room or not based on their medical history. Understanding the medical history of a patient is a very complex problem, and the developers of the algorithm made the assumption that people with a severe medical history will spend more money on healthcare than others. They therefore used the amount of money previously spent on healthcare as a substitute for medical history. However, due to socio-economical reasons, black Americans spend on average less money on healthcare than white Americans with similar needs. Therefore, the algorithm systematically underestimated black American’s medical needs. Data itself is not the issue here.
It is important to note that algorithmic biases go much further than sexist or racist biases. For instance, researchers have been studying &lt;a href=&#34;https://arxiv.org/abs/2406.08818&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;linguistic biases in ChatGPT&lt;/a&gt; and demonstrated that it is stereotyping dialects, which made users of these dialects feel uncomfortable and insulted.  Cultural biases or misrepresentations are other issues associated to AI systems.&lt;/p&gt;
&lt;p&gt;Why does it matter? After all, if we know these systems are biased, can’t we check the output ourselves and make our own mind? Unfortunately, it is not that simple. We all have a tendency to favor decisions made with automation compared to decision made without. This is called automation bias, and is well studied in psychology. This means that when AI systems present us with a solution, we are naturally inclined to adopt this solution. Yes, this applies even if you are aware that automation bias is a thing. Furthermore, researchers have also shown that using AI systems directly impacts our opinions. &lt;a href=&#34;https://arxiv.org/abs/2302.00560&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;In a study&lt;/a&gt;, a language model was programmed to promote a specific opinion towards social media. Participants who used this model wrote pieces that followed the promoted opinion, and even had their own stance towards social media influenced by the model. This is a frightening find. More and more text is being written with the help of ChatGPT and other AI assistants, and we have no control over the opinions programmed in them. Beyond text, AI systems are creating images, moderating content, and generally following rules and algorithms that we have no control over and belong to a handful of very rich companies. What we see, what we read, what we and our children take as role models. All of that is being fed to us by AIs, and we have no say in it.&lt;/p&gt;
&lt;p&gt;Or do we?&lt;/p&gt;
&lt;p&gt;AI must become a citizen concern. As we vote about economy, environment, social policies, we must also vote about AI, its development and its adoption. We don’t need to become AI experts any more that we needed to become geopolitical experts, or financial experts. However, we have a duty to educate ourselves, to understand who is talking about AI on the world’s stage and wonder about the consequences of what they are saying. We must reflect on what we want and how we want it to be. AI is now, more than ever, political. We cannot remain the passive observers of what is happening to us. We can and must have a say in it.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The CHAI Workshop is coming back in Malmö in June</title>
      <link>https://jrenoux.github.io/talks-events/20240315-chai-hhai/</link>
      <pubDate>Sat, 09 Mar 2024 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/talks-events/20240315-chai-hhai/</guid>
      <description>&lt;p&gt;Our Workshop on Communication in Human-AI Interaction will be held in Malmö, Sweden on June 10. The goal of this one-day workshop is to bring together experts from AI, HCI, and Cognitive Sciences to explore and understand the specificities and characteristics of communication in human-AI interactions, as well as the salient principles, methods, and theories one has to consider to build meaningful human-AI communication systems. As the study of communication in human-AI interaction is by essence a multidisciplinary approach, we aim for this workshop to be a multidisciplinary platform where researchers can learn to work together and pave the way to impacting research.&lt;/p&gt;
&lt;p&gt;Have a look at our &lt;a href=&#34;https://chai-workshop.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;website&lt;/a&gt;. and consider submitting a paper!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Visual Noun Modifiers: The Problem of Binding Visual and Linguistic Cues</title>
      <link>https://jrenoux.github.io/publication/faridghasemnia-2024-visual/</link>
      <pubDate>Thu, 01 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/faridghasemnia-2024-visual/</guid>
      <description></description>
    </item>
    
    <item>
      <title>When Should I Lead or Follow: Understanding Initiative Levels in Human-AI Collaborative Gameplay</title>
      <link>https://jrenoux.github.io/publication/lobo-2024-when/</link>
      <pubDate>Thu, 01 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/lobo-2024-when/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Paper accepted ! From Corrective to Empowering Technologies: Integrating Critical Perspectives in Social Robotics for Autism</title>
      <link>https://jrenoux.github.io/talks-events/20231207-interhai/</link>
      <pubDate>Thu, 30 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/talks-events/20231207-interhai/</guid>
      <description>&lt;p&gt;Our new extended abstract titled &amp;ldquo;From Corrective to Empowering Technologies: Integrating Critical Perspectives in Social Robotics for Autism&amp;rdquo; has been accepted for presentation at the Inter.HAI workshop! In this paper, we look at how the social robotics field usually look at autism as a problem that needs to be corrected, and introduce two approaches that are of interest for social robotics researchers who want to adopt a more critical approach. You can access the paper &lt;a href=&#34;https://jrenoux.github.io/uploads/papers/interhai-2023-cei-jrx.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Large Language Models &#43; Giant AI Experiments = A Whole New World?</title>
      <link>https://jrenoux.github.io/talks-events/20231019-linnaeus-university/</link>
      <pubDate>Thu, 19 Oct 2023 10:10:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/talks-events/20231019-linnaeus-university/</guid>
      <description>&lt;p&gt;On October 19th, I gave a talk at the Research Seminar eHealth Series, organized by Health Data Sweden, about LLM and how they change (or not) the world we are living in.&lt;/p&gt;
&lt;p&gt;Thanks a lot to the organizers for inviting me! You can find the slides of my presentation &lt;a href=&#34;https://jrenoux.github.io/uploads/talks/20231019-llm-linnaeus.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Beyond the Hype: Perspectives on the use of AI and LLM at the university</title>
      <link>https://jrenoux.github.io/talks-events/oru-business-school/</link>
      <pubDate>Tue, 29 Aug 2023 16:45:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/talks-events/oru-business-school/</guid>
      <description>&lt;p&gt;On August 23rd, I had the pleasure of talking in front of Örebro University&amp;rsquo;s buisness school about LLM, what they are, and how they may change our university work.&lt;/p&gt;
&lt;p&gt;Thanks a lot to the organizers for inviting me! You can find the slides of my presentation &lt;a href=&#34;https://jrenoux.github.io/uploads/talks/ethics-ai-llm-university.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>From Corrective to Empowering Technologies: Integrating Critical Perspectives in Social Robotics for Autism</title>
      <link>https://jrenoux.github.io/publication/elmadagli-2023-from/</link>
      <pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/elmadagli-2023-from/</guid>
      <description></description>
    </item>
    
    <item>
      <title>From Reactive to Active Sensing: A Survey on Information Gathering in Decision-Theoretic Planning</title>
      <link>https://jrenoux.github.io/publication/veiga-2023-from/</link>
      <pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/veiga-2023-from/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Paper accepted ! &#34;From Reactive to Active Sensing: a Survey on Information Gathering in Decision-Theoretic Planning</title>
      <link>https://jrenoux.github.io/talks-events/csur-23/</link>
      <pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/talks-events/csur-23/</guid>
      <description>&lt;p&gt;Our new paper titled &amp;ldquo;From Reactive to Active Sensing: a Survey on Information Gathering in Decision-Theoretic Planning&amp;rdquo; has ben accepted for publication in ACM Computing Survey.&lt;/p&gt;
&lt;p&gt;In this paper, we looked at how previous work tackled the problem of information gathering in MDP-based system. Indeed, in most cases, information gathering is simply a mean to a goal. When it becomes the goal, such as in search and rescue or surveillance scenarios, traditional decision-theoretic systems cannot model the problem effectively. Many researchers have searched ways to circumvent this problem. We distinguished two different approaches:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Reactive Sensing : where the model makes use of &amp;ldquo;external stimuli&amp;rdquo; to &amp;ldquo;trick&amp;rdquo; the agent to gather information. This approach is often very application-dependent, and does not allow to reason on the lack of informtaion as information in itself.&lt;/li&gt;
&lt;li&gt;Active Sensing : where the model actually incorporates reasoning about information states. This approach has the advantage to explicety reason about information gain (and the lack of thereof) but at the cost of complexity. We also observed that it is in fact very seldom applied to real-life scenarios.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I hope that this read will interest you and do not hesitate to get in touch if you want to chat about this!&lt;/p&gt;
&lt;p&gt;Jennifer&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Seeking at-home long-term autonomy of assistive mobile robots through the integration with an IoT-based monitoring system</title>
      <link>https://jrenoux.github.io/publication/luperto-2023-seeking/</link>
      <pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/luperto-2023-seeking/</guid>
      <description></description>
    </item>
    
    <item>
      <title>VR Project Grant Accepted</title>
      <link>https://jrenoux.github.io/talks-events/vr-2022/</link>
      <pubDate>Tue, 08 Nov 2022 10:22:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/talks-events/vr-2022/</guid>
      <description>&lt;p&gt;The project proposal I&amp;rsquo;m leading, titled &amp;ldquo;Adaptive Communication Planning for Collaborative AI&amp;rdquo;, has been funded by the Swedish National Research Council (Vetenskaprådet).&lt;/p&gt;
&lt;p&gt;To understand this project&amp;rsquo;s scope, imagine that you are newly employed in a company that uses three types of intelligent machines to assist workers in their various tasks. You have never worked with these machines before. For your first task, you must extract fuel samples from multiple trucks and use the machine’s sensors to analyze them for predictive maintenance. The first machine will only give you information about the task if you ask for it. You are at high risk of missing important information if you don’t know the right question to ask, such as the fact that you should only collect samples on trucks that have not been used for at least an hour.&lt;/p&gt;
&lt;p&gt;The second machine will give you information proactively, but can only explain how the entire task should be carried out, from the beginning and regardless of what you can and cannot perform. It will always instruct you to select a truck that has been unused for at least an hour, then collect the sample with the dedicated device, then place the sample on the machine’s analyzer, then turn on the robot’s analyzing program, etc. While this information makes sense the first time you interact with the machine, it becomes quickly irrelevant and cumbersome in the long term.&lt;/p&gt;
&lt;p&gt;The third machine has been tailored to your needs: your preferences, your level of expertise, your skills, your abilities and will give you precisely the right amount and type of information. However, if you happen to leave the company or miss some days of work, no one will be able to use this machine until it is reconfigured, which is a costly and cumbersome operation.&lt;/p&gt;
&lt;p&gt;It seems obvious that none of these three machines constitute the ideal partner for a collaborative task in a multi-user environment. This, however, is the current state of the art in
human-machine communication. In this project, we propose to realize intelligent agents that combine all three machine&amp;rsquo;s communication skills.&lt;/p&gt;
&lt;p&gt;Our vision with this project is to advance the field of collaborative Artificial Intelligence, i.e., the development of artificially intelligent agents that can interact with humans, leveraging their strengths and compensating for their weaknesses.  Adaptive purposeful communication planning, i.e., the ability to plan communication actions to a given goal and adapt them to changing contexts and users, is a crucial component for collaborative AI and the central topic of this project.&lt;/p&gt;
&lt;p&gt;If this sounds interesting to you, stay tuned as we will soon start the recruitment of a Ph.D. student!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>AI Ethic for Engineers, Swedsoft</title>
      <link>https://jrenoux.github.io/talks-events/swedsoft/</link>
      <pubDate>Tue, 20 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/talks-events/swedsoft/</guid>
      <description>&lt;p&gt;On Sept. 6, 2022, I had the pleasure of presenting an Introduction to AI Ethics and Engineer at one of Swedsoft Seminars. Swedsoft gathers organizations from all over Sweden who are interested in software development.&lt;/p&gt;
&lt;p&gt;Thanks a lot to the organizers for inviting me! You can find the slides of my presentation &lt;a href=&#34;https://jrenoux.github.io/uploads/talks/swedsoft-slides.pdf&#34;&gt;here&lt;/a&gt; and more information about this event at &lt;a href=&#34;https://www.swedsoft.se/en/2022/09/26/ai-and-ethics-for-engineer/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Swedsoft website&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Cultu-RO-MAN</title>
      <link>https://jrenoux.github.io/talks-events/cultu-roman/</link>
      <pubDate>Tue, 30 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/talks-events/cultu-roman/</guid>
      <description>&lt;p&gt;On August 25, 2022, we hosted the Cultu-ro workshsop at Ro-MAN 2022. The workshop will focused on the cultural influences in human-robot interaction. Robots have the potential to improve services in areas such as eldercare, rehabilitation, training, and education.&lt;/p&gt;
&lt;p&gt;More information and detail of the program available &lt;a href=&#34;https://sites.google.com/view/culturo-roman22/home&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;on the workshop website&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>CHAI@IJCAI-ECAI 2022</title>
      <link>https://jrenoux.github.io/talks-events/chai-ijcai/</link>
      <pubDate>Mon, 01 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/talks-events/chai-ijcai/</guid>
      <description>&lt;p&gt;On July 24, 2022, we hosted the first workshop on Communication in Human-AI Interaction (CHAI) at the 31st International Joint Conference on Artificial Intelligence (IJCAI 2022). The goal of this one-day workshop was to bring together experts from AI, HCI, and Cognitive Sciences to explore and understand the specificities and characteristics of communication in human-AI interactions, as well as the salient principles, methods, and theories one has to consider to build meaningful human-AI communication systems.&lt;/p&gt;
&lt;p&gt;We attended 8 paper presentations, as well as two very inspiring keynotes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Nicolas Fay&lt;/strong&gt;, Associate Professor of Cognitive Sciences, presented to us the Role of Iconicity and Embodiment to the Evolution of Human Communication.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Mark Riedl&lt;/strong&gt;, Professor in Artificial Intelligence, argumed for Automated Story Generation as a Lens for Fundamental Artificial Intelligence.&lt;/p&gt;
&lt;p&gt;We were very glad to have a very good attendance and fantastic discussions. Thanks to the organizing team, the PC members, and all the participants for making this event a success!&lt;/p&gt;
&lt;p&gt;The link to the accepted papers and the slides of our keynotes are available on the &lt;a href=&#34;https://chai-workshop.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;workshop website&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Stay tuned, for a 2023 edition might be coming! 😉&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Integrating Social Assistive Robots, IoT, Virtual Communities and Smart Objects to Assist at-Home Independently Living Elders: the MoveCare Project</title>
      <link>https://jrenoux.github.io/publication/luperto-2022-integrating/</link>
      <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/luperto-2022-integrating/</guid>
      <description></description>
    </item>
    
    <item>
      <title>User feedback and remote supervision for assisted living with mobile robots: A field study in long-term autonomy</title>
      <link>https://jrenoux.github.io/publication/luperto-2022-user/</link>
      <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/luperto-2022-user/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Unified Decision-Theoretic Model for Information Gathering and Communication Planning</title>
      <link>https://jrenoux.github.io/publication/renoux-2020-unified/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/renoux-2020-unified/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Virtual Caregiver for Assisted Daily Living of Pre-frail Users</title>
      <link>https://jrenoux.github.io/publication/renoux-2020-virtual/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/renoux-2020-virtual/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Open-Source Data Collection and Data Sets for Activity Recognition in Smart Homes</title>
      <link>https://jrenoux.github.io/publication/kockemann-2020-open/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/kockemann-2020-open/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Users&#39; Concern for Privacy in Context-Aware Reasoning Systems</title>
      <link>https://jrenoux.github.io/publication/forstmann-2020-users/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/forstmann-2020-users/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://jrenoux.github.io/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-wowchemy&#34;&gt;Create slides in Markdown with Wowchemy&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wowchemy&lt;/a&gt; | &lt;a href=&#34;https://wowchemy.com/docs/content/slides/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://revealjs.com/pdf-export/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;porridge&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;blueberry&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;porridge&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;blueberry&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Eating...&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% fragment %}} One {{% /fragment %}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% fragment %}} **Two** {{% /fragment %}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% fragment %}} Three {{% /fragment %}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;span class=&#34;fragment &#34; &gt;
  One
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
  &lt;strong&gt;Two&lt;/strong&gt;
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
  Three
&lt;/span&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% speaker_note %}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;-&lt;/span&gt; Only the speaker can read these notes
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;-&lt;/span&gt; Press &lt;span class=&#34;sb&#34;&gt;`S`&lt;/span&gt; key to view
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  {{% /speaker_note %}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;slide&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;background-image&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;/media/boards.jpg&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;slide&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;background-color&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;#0000FF&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;slide&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;class&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;my-style&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-css&#34; data-lang=&#34;css&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;reveal&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;section&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;h1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;reveal&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;section&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;h2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;reveal&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;section&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;h3&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;color&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;navy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://discord.gg/z8wNYzb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/docs/content/slides/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The MOVECARE project: Home-based monitoring of frailty</title>
      <link>https://jrenoux.github.io/publication/lunardini-2019-movecare/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/lunardini-2019-movecare/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Online Guest Detection in a Smart Home using Pervasive Sensors and Probabilistic Reasoning</title>
      <link>https://jrenoux.github.io/publication/renoux-2018-online/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/renoux-2018-online/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Seeking Prevention of Cognitive Decline in Elders via Activity Suggestion by A Virtual Caregiver.</title>
      <link>https://jrenoux.github.io/publication/vuono-2018-seeking/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/vuono-2018-seeking/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Simulating Daily Activities in a Smart Home for Data Generation</title>
      <link>https://jrenoux.github.io/publication/renoux-2018-simulating/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/renoux-2018-simulating/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Active Situation Reporting: Definition and Analysis</title>
      <link>https://jrenoux.github.io/publication/renoux-2017-active/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/renoux-2017-active/</guid>
      <description></description>
    </item>
    
    <item>
      <title>An ontology-based context-aware system for smart homes: E-care@ home</title>
      <link>https://jrenoux.github.io/publication/alirezaie-2017-ontology/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/alirezaie-2017-ontology/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Context recognition in multiple occupants situations: Detecting the number of agents in a smart home environment with simple sensors</title>
      <link>https://jrenoux.github.io/publication/renoux-2017-context/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/renoux-2017-context/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Towards a synergy of qualitative spatio-temporal reasoning and smart environments for assisting the elderly at home</title>
      <link>https://jrenoux.github.io/publication/sioutis-2017-towards/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/sioutis-2017-towards/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A decision-theoretic planning approach for multi-robot exploration and event search</title>
      <link>https://jrenoux.github.io/publication/renoux-2015-decision/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/renoux-2015-decision/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Contribution to multiagent planning for active information gathering</title>
      <link>https://jrenoux.github.io/publication/renoux-2015-contribution/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/renoux-2015-contribution/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Method For Obtaining A System For Active, Decentralized Multi-agent Situation Control</title>
      <link>https://jrenoux.github.io/publication/renoux-2015-method/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/renoux-2015-method/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Distributed Decision-Theoretic Model for Multiagent Active Information Gathering</title>
      <link>https://jrenoux.github.io/publication/renoux-2014-distributed/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/renoux-2014-distributed/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Un modèle de décision distribué pour la collecte d&#39;information active multiagents</title>
      <link>https://jrenoux.github.io/publication/renoux-2014-modele/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/renoux-2014-modele/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Affective computing: validation analytique et expérimentale</title>
      <link>https://jrenoux.github.io/publication/renoux-2011-affective/</link>
      <pubDate>Sat, 01 Jan 2011 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/publication/renoux-2011-affective/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://jrenoux.github.io/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://jrenoux.github.io/admin/config.yml</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
